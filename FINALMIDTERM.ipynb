{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Midterm\n",
        "Steps\n",
        "\n",
        "1) Data pre-processing:\n",
        "Clean and prepare your data by removing irrelevant characters, handling missing values, and converting text to numerical features using NLP techniques.\n",
        "\n",
        "2) Feature engineering:\n",
        "Extract relevant features from the reviews like sentiment scores, keyword counts, and review length.\n",
        "\n",
        "3) Model selection and tuning:\n",
        "Try different models and tune hyperparameters to find the best performing one for your data.\n",
        "\n",
        "4) Evaluation metrics:\n",
        "Use metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE), or R-squared to assess the model's performance."
      ],
      "metadata": {
        "id": "uDRdgGM3V9Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOaLji3S1ZAS",
        "outputId": "ab4e342e-b115-4812-ed5c-84a19928af53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrS5zlmllrEu"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import string\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data set\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "i3yU9_akW4kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge test_data with train_data to get metadata for each 'Id'\n",
        "test_data = test_data.merge(train_data, on=\"Id\", how=\"left\")\n",
        "test_data.head() #will deal with processing later...."
      ],
      "metadata": {
        "collapsed": true,
        "id": "haCrizPLzC96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Data Preprocessing/Cleaning"
      ],
      "metadata": {
        "id": "6deZzKefznDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixing Helpfulness, no Nans\n",
        "train_data.loc[train_data['HelpfulnessDenominator'] == 0, 'HelpfulnessDenominator'] = 1\n",
        "train_data['HelpfulnessNumerator'] = train_data['HelpfulnessNumerator'].fillna(0)\n",
        "train_data['HelpfulnessDenominator'] = train_data['HelpfulnessDenominator'].fillna(1)\n",
        "\n",
        "#dropping all rows where text is missing cuz thats kinda the main thing we are basing our system off of\n",
        "train_data = train_data.dropna(subset=[\"Text\"])\n",
        "train_data = train_data.dropna(subset=[\"Summary\"])\n",
        "\n",
        "#dropping all irrelvant rows that dont add value to the prediction.... maybe add Summary back here\n",
        "train_data = train_data.drop(columns=[\"Id\",\"ProductId\",\"UserId\"])\n",
        "train_data = train_data.dropna(subset=[\"Score\"])\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "1XfTr9_PPQDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Feature Engineering"
      ],
      "metadata": {
        "id": "mMZUbstq0I-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new feature FullText that is just a combo of Summary and Text & dropping now irrelvant features\n",
        "train_data['FullText'] = train_data['Summary'] + \" \" + train_data['Text']\n",
        "train_data = train_data.drop(columns=[\"Summary\",\"Text\"])\n",
        "\n",
        "#Creating new feature Helpfulness Ratio & dropping now irrelevant features\n",
        "train_data['HelpfulnessRatio'] = train_data['HelpfulnessNumerator'] / (train_data['HelpfulnessDenominator'] + 1e-5)\n",
        "train_data = train_data.drop(columns=[\"HelpfulnessNumerator\",\"HelpfulnessDenominator\"])\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "dkbbNvsS0L5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Steps for getting rid of all the stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    #Converting to lowercase\n",
        "    text = str(text).lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove stop words\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "#train_data = train_data.sample(n=20000, random_state=42) #using this so I can make processing faster\n",
        "train_data['FullText'] = train_data['FullText'].apply(preprocess_text)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "hbeMkAQpSk8T",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TF-IDF on the 'Text' column to convert text to numerical features\n",
        "tfidf = TfidfVectorizer(max_df=0.05, max_features=500, ngram_range=(1, 2))\n",
        "tfidf_matrix = tfidf.fit_transform(train_data[\"FullText\"])\n",
        "\n",
        "#Reducing the TFIDF matrix\n",
        "n_components = 50  # Choose the number of components\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "#Getting our X and y\n",
        "X = pd.concat([train_data[[\"HelpfulnessRatio\", \"Time\"]].reset_index(drop=True),pd.DataFrame(reduced_matrix)], axis=1)\n",
        "X.columns = X.columns.astype(str)\n",
        "y = train_data[\"Score\"]"
      ],
      "metadata": {
        "id": "VPjz7V6gTaDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "WiP0HC4A3gSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3.1: Model Selection"
      ],
      "metadata": {
        "id": "p8Qfqz7Y3Ehj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "dVFHKX8MU5KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Model\n",
        "rf_model = RandomForestClassifier(class_weight='balanced',random_state=42, max_depth=12, min_samples_leaf=4,min_samples_split=2,n_estimators=300)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set for random Forest\n",
        "y_predrf = rf_model.predict(X_test)\n",
        "print(\"Random Forest:\")\n",
        "print(classification_report(y_test, y_predrf))\n",
        "print(\"cross-validation score:\")\n",
        "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
        "print(cv_scores.mean())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l_zbDltSVvA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB model\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "y_train = y_train - 1\n",
        "y_test = y_test - 1\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "y_predXGB = xgb_model.predict(X_test)\n",
        "print(\"XGB:\")\n",
        "print(classification_report(y_test, y_predXGB))\n",
        "print(\"cross-validation score:\")\n",
        "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5)\n",
        "print(cv_scores.mean())"
      ],
      "metadata": {
        "id": "14Obm399XHKj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3.2: Comparing Models & Tuning Hyper Parameters"
      ],
      "metadata": {
        "id": "hP21hQTLFjQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example for a Random Forest model\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 20, 70],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=5,\n",
        "                           n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validated score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "XXT9CauUFSpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Predicting our Testing Data & Evaluating"
      ],
      "metadata": {
        "id": "TIuaQWG75j7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "HutsdBBk-UOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the testing data for prediction\n",
        "#Fixing Helpfulness, no Nans\n",
        "test_data.loc[test_data['HelpfulnessDenominator'] == 0, 'HelpfulnessDenominator'] = 1\n",
        "test_data['HelpfulnessNumerator'] = test_data['HelpfulnessNumerator'].fillna(0)\n",
        "test_data['HelpfulnessDenominator'] = test_data['HelpfulnessDenominator'].fillna(1)\n",
        "\n",
        "#dropping all rows where text is missing cuz thats kinda the main thing we are basing our system off of\n",
        "test_data = test_data.dropna(subset=[\"Text\"])\n",
        "test_data = test_data.dropna(subset=[\"Summary\"])\n",
        "\n",
        "#dropping all irrelvant rows that dont add value to the prediction.... maybe add Summary back here\n",
        "test_data = test_data.drop(columns=[\"ProductId\",\"UserId\",\"Score_y\"])\n",
        "\n",
        "#Creating new feature FullText that is just a combo of Summary and Text & dropping now irrelvant features\n",
        "test_data['FullText'] = test_data['Summary'] + \" \" + test_data['Text']\n",
        "test_data = test_data.drop(columns=[\"Summary\",\"Text\"])\n",
        "\n",
        "#Creating new feature Helpfulness Ratio & dropping now irrelevant features\n",
        "test_data['HelpfulnessRatio'] = test_data['HelpfulnessNumerator'] / (test_data['HelpfulnessDenominator'] + 1e-5)\n",
        "test_data = test_data.drop(columns=[\"HelpfulnessNumerator\",\"HelpfulnessDenominator\"])\n",
        "test_data.head()\n",
        "\n",
        "##test_data = test_data.sample(n=1000, random_state=42)\n",
        "test_data['FullText'] = test_data['FullText'].apply(preprocess_text)\n",
        "\n",
        "# Use TF-IDF on the 'Text' column to convert text to numerical features\n",
        "tfidf = TfidfVectorizer(max_df=0.05, max_features=500, ngram_range=(1, 2))\n",
        "tfidf_matrix = tfidf.fit_transform(test_data[\"FullText\"])\n",
        "\n",
        "#Reducing the TFIDF matrix\n",
        "n_components = 50  # Choose the number of components\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "#Getting our X and y\n",
        "X = pd.concat([test_data[[\"HelpfulnessRatio\", \"Time\"]].reset_index(drop=True),pd.DataFrame(reduced_matrix)], axis=1)\n",
        "X.columns = X.columns.astype(str)"
      ],
      "metadata": {
        "id": "83xoCXfE-ueF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "TIrt1uusGi8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[\"Score_x\"] = rf_model.predict(X)"
      ],
      "metadata": {
        "id": "sHrMAsTWDQJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "tJwxv5WGGp02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "test_data['Score_x'].plot(kind='hist', bins=20, title='Score_x')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "bJWvdlISGwJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving Predictions for Submission\n",
        "submission = test_data[[\"Id\", \"Score_x\"]]\n",
        "submission.to_csv(\"predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "AdXUA3nPF7Zb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}